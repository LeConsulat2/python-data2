# Import necessary libraries
import streamlit as st
import pandas as pd
import json
import re
from dotenv import load_dotenv
import os
import google.generativeai as genai # ì£¼ì„: Gemini APIë¥¼ ìœ„í•œ ìƒˆë¡œìš´ ì„í¬íŠ¸
import numpy as np # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ ì‹œ numpyë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¯¸ë¦¬ ì„í¬íŠ¸ (exec í™˜ê²½ì— ì£¼ì…)

# ì£¼ì„: í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì˜ˆ: .env íŒŒì¼ì—ì„œ GEMINI_API_KEY ë¡œë“œ)
load_dotenv()

# ì£¼ì„: Gemini API í‚¤ ì„¤ì •. í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ê°€ ì—†ëŠ” ê²½ìš° ì•±ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("`GEMINI_API_KEY` environment variable not set. Please set it in your `.env` file.")
    st.stop() # Stops the Streamlit app if API key is missing

# ì£¼ì„: Gemini ëª¨ë¸ ì´ˆê¸°í™”
try:
    genai.configure(api_key=GEMINI_API_KEY)
except Exception as e:
    st.error(f"Failed to configure Gemini API: {e}. Please check your API key.")
    st.stop()

# --- LLM API Configuration ---
# ì£¼ì„: LLM ëª¨ë¸ ì´ë¦„ ì •ì˜. Gemini 1.5 FlashëŠ” ë¹ ë¥¸ ì‘ë‹µê³¼ ëŒ€ê·œëª¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
GEMINI_MODEL_NAME = "gemini-1.5-flash"
TEMPERATURE = 0.2  # ì£¼ì„: LLMì˜ ì°½ì˜ì„± ì¡°ì ˆ. 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€.
MAX_OUTPUT_TOKENS = 4096 # ì£¼ì„: LLM ì‘ë‹µì˜ ìµœëŒ€ í† í° ìˆ˜. ì½”ë“œ ìƒì„±ì— ì¶©ë¶„í•œ í¬ê¸°.

# --- LLM Call Function ---
def call_gemini_api(prompt: str) -> str:
    """
    # ì£¼ì„: ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œ Gemini LLMì„ ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
    # ì£¼ì„: ì´ëŠ” ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ LLMì—ê²Œ ì „ë‹¬í•˜ëŠ” ì¼ë°˜ì ì¸ í—¬í¼ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        model = genai.GenerativeModel(GEMINI_MODEL_NAME)
        # ì£¼ì„: LLM ì‘ë‹µ ìƒì„±ì„ ìœ„í•œ êµ¬ì„± ì„¤ì •
        generation_config = {
            "temperature": TEMPERATURE,
            "max_output_tokens": MAX_OUTPUT_TOKENS,
            "response_mime_type": "text/plain", # ì£¼ì„: ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ê¸°ëŒ€í•©ë‹ˆë‹¤.
        }
        
        # ì£¼ì„: LLMì— ë³´ë‚¼ ë©”ì‹œì§€ (ë‹¨ì¼ ì‚¬ìš©ì ë©”ì‹œì§€)
        messages = [{"role": "user", "parts": [prompt]}]
        
        st.info(f"Calling Gemini {GEMINI_MODEL_NAME}...") # ì£¼ì„: LLM í˜¸ì¶œ ì‹œì‘ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.
        
        response = model.generate_content(
            messages,
            generation_config=generation_config
        )
        
        # ì£¼ì„: ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        return response.text
    except Exception as e:
        # ì£¼ì„: LLM API í˜¸ì¶œ ì¤‘ ë°œìƒí•œ ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        st.error(f"Error calling Gemini API: {e}. Please check your API key or network connection.")
        return f"ERROR: LLM API call failed: {e}"

# --- Prompt Engineering Functions ---

def generate_code_prompt(user_query: str, df_preview: dict, df_types: dict) -> str:
    """
    # ì£¼ì„: ì‚¬ìš©ì ì§ˆì˜ì™€ DataFrameì˜ ë¯¸ë¦¬ë³´ê¸° ë° íƒ€ì… ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Python ì½”ë“œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    # ì£¼ì„: ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLMì´ ê²¬ê³ í•˜ê³  ì •í™•í•œ Pandas ì½”ë“œë¥¼ ìƒì„±í•˜ë„ë¡ ìƒì„¸í•œ ì§€ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.
    """
    # ì£¼ì„: DataFrame ë¯¸ë¦¬ë³´ê¸° ë° íƒ€ì… ì •ë³´ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    # ì£¼ì„: ensure_ascii=FalseëŠ” í•œêµ­ì–´ ë¬¸ìë¥¼ ì˜¬ë°”ë¥´ê²Œ í¬í•¨í•˜ê¸° ìœ„í•´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    preview_str = json.dumps(df_preview, ensure_ascii=False, indent=2)
    types_str = json.dumps(df_types, ensure_ascii=False, indent=2)

    # ì£¼ì„: ì½”ë“œ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±. LLMì˜ ì—­í• ì„ ëª…í™•íˆ í•˜ê³ , ê¸°ëŒ€í•˜ëŠ” ì½”ë“œì˜ íŠ¹ì„±ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤.
    prompt = f"""
    You are an expert Python data analyst assistant. Your task is to generate robust and correct Pandas Python code to analyze a DataFrame named `df`.
    The code will be executed in an environment where `pandas` is imported as `pd`, and `numpy` is imported as `np`.

    Here's a preview of the DataFrame `df` (first 5 rows):
    ```json
    {preview_str}
    ```

    And here are the detected data types for each column in `df`:
    ```json
    {types_str}
    ```

    The user's specific request for analysis is: "{user_query}"

    **Crucial Instructions for Code Generation:**
    1.  **Assume `df` is loaded:** Your code should operate on a DataFrame variable already named `df`.
    2.  **Return `final_df`:** The ultimate result of your analysis MUST be assigned to a new Pandas DataFrame variable named `final_df`. This `final_df` will be used for further summarization.
    3.  **Contextual Results:** Even if the user's query asks for a single metric (e.g., maximum, minimum, top 1 item), the `final_df` must provide **full relevant context**. For example, if the query is "Which district has the highest building floor count?", `final_df` should return a DataFrame that includes the district, the floor count, and possibly other related columns, sorted or filtered to highlight the answer, not just the name of the top district. This provides a richer and verifiable context.
    4.  **Handle Data Issues Robustly:**
        *   **Missing Values (NaNs):** Be prepared to handle `NaN`s using methods like `.dropna()`, `.fillna()`, or by ensuring aggregation methods gracefully handle missing data.
        *   **Incorrect Data Types:** Explicitly convert column types using `.astype()` (e.g., `pd.to_numeric(df['col'], errors='coerce')`, `df['col'].astype(str)`, `pd.to_datetime(df['col'], errors='coerce')`) *before* performing numerical, date, or string operations if the inferred types in `df_types` might cause errors. Use `errors='coerce'` for numeric/datetime conversions to turn unparseable values into `NaN` instead of raising an error.
        *   **Key Errors:** Double-check column names against `df_preview` and `df_types` to avoid `KeyError` if a column name is slightly off.
    5.  **No External Code:** Your code MUST NOT include any `import` statements or `print()` calls. Only pure Pandas/Python logic is allowed.
    6.  **Output Format:** Enclose your entire Python code block within `<result></result>` XML tags.

    ## Example of Desired Output Structure:
    <result>
    # Example: Find the top 3 administrative districts by total 'ì¸µìˆ˜' (floor count)
    df['ì¸µìˆ˜'] = pd.to_numeric(df['ì¸µìˆ˜'], errors='coerce') # Ensure 'ì¸µìˆ˜' is numeric
    floor_counts = df.groupby('í–‰ì •êµ¬')['ì¸µìˆ˜'].sum().reset_index()
    sorted_districts = floor_counts.sort_values(by='ì¸µìˆ˜', ascending=False)
    final_df = sorted_districts.head(3) # Provide contextual data, not just the top one name
    </result>
    """
    return prompt

def extract_code_from_response(response: str) -> str:
    """
    # ì£¼ì„: LLMì˜ í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ Python ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    # ì£¼ì„: <result> íƒœê·¸ ë‚´ë¶€ ë˜ëŠ” ì¼ë°˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ ì½”ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    # 1. Try to extract from <result> tags first (most reliable)
    match = re.search(r"<result>(.*?)</result>", response, re.DOTALL)
    if match:
        code_block = match.group(1)
        # ì£¼ì„: <result> íƒœê·¸ ì•ˆì— ë§ˆí¬ë‹¤ìš´ ì½”ë“œ íœìŠ¤ê°€ ìˆëŠ” ê²½ìš° ì´ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        code_block = re.sub(r"```(?:python)?", "", code_block).strip()
        return code_block

    # 2. If <result> tags are not found, try common markdown code blocks
    match = re.search(r"```(?:python)?(.*?)```", response, re.DOTALL)
    if match:
        return match.group(1).strip()

    # ì£¼ì„: ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê²½ê³  ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
    st.warning("Could not extract any valid Python code from the LLM's response. Please ensure it's wrapped in `<result></result>` tags or markdown code blocks.")
    return ""

def execute_generated_code(code: str, df: pd.DataFrame, max_retries: int = 3) -> pd.DataFrame | str:
    """
    # ì£¼ì„: ìƒì„±ëœ Python ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³ , ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ LLMì—ê²Œ ì½”ë“œ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©° ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    # ì£¼ì„: ìµœì¢…ì ìœ¼ë¡œ Pandas DataFrameì„ ë°˜í™˜í•˜ê±°ë‚˜ ì˜¤ë¥˜ ë©”ì‹œì§€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    current_code = code
    error_history = [] # ì£¼ì„: ì´ì „ ì˜¤ë¥˜ ë©”ì‹œì§€ë“¤ì„ ê¸°ë¡í•©ë‹ˆë‹¤.
    
    st.info("Attempting to execute the generated Python code...") # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ ì‹œë„ ì•Œë¦¼

    for attempt in range(max_retries):
        try:
            # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¡œì»¬ ë³€ìˆ˜ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤.
            # ì£¼ì„: df, final_df ì™¸ì— pd (pandas)ì™€ np (numpy)ë¥¼ ë¯¸ë¦¬ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì£¼ì…í•©ë‹ˆë‹¤.
            local_vars = {"df": df, "final_df": None, "pd": pd, "np": np}
            
            # ì£¼ì„: ìƒì„±ëœ Python ì½”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
            # ì£¼ì„: __builtins__=Noneì€ ë‚´ì¥ í•¨ìˆ˜(ì˜ˆ: print) ì‚¬ìš©ì„ ì œí•œí•©ë‹ˆë‹¤.
            exec(current_code, {"__builtins__": None}, local_vars)
            
            # ì£¼ì„: ì‹¤í–‰ ê²°ê³¼ë¡œ final_dfê°€ ìœ íš¨í•œ Pandas DataFrameì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
            result_df = local_vars.get("final_df")
            if isinstance(result_df, pd.DataFrame):
                st.success(f"Code executed successfully on attempt {attempt + 1}!") # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ ì„±ê³µ ë©”ì‹œì§€
                return result_df
            else:
                # ì£¼ì„: final_dfê°€ DataFrameì´ ì•„ë‹ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
                raise ValueError("The generated code did not return a pandas DataFrame named `final_df` or `final_df` is not a DataFrame.")

        except Exception as e:
            error_message = str(e)
            error_history.append(f"Attempt {attempt + 1} failed with error: {error_message}")
            st.error(f"Code execution failed on attempt {attempt + 1}: `{error_message}`") # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ ë©”ì‹œì§€
            
            if attempt < max_retries - 1:  # ì£¼ì„: ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì¬ì‹œë„ ë° ì½”ë“œ ìˆ˜ì • ìš”ì²­
                st.info(f"Requesting LLM to correct the code (attempt {attempt + 1}/{max_retries})...") # ì£¼ì„: LLMì— ì½”ë“œ ìˆ˜ì • ìš”ì²­ ì•Œë¦¼
                # ì£¼ì„: ì½”ë“œ ìˆ˜ì •ì„ ìœ„í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
                # ì£¼ì„: ì´ì „ ì½”ë“œ, ì˜¤ë¥˜ ë©”ì‹œì§€, ê·¸ë¦¬ê³  ì´ì „ ì˜¤ë¥˜ ê¸°ë¡ì„ ì œê³µí•˜ì—¬ LLMì´ ë§¥ë½ì„ ì´í•´í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.
                error_prompt = f"""
                The following Python code failed during execution:
                ```python
                {current_code}
                ```
                
                The specific error message received was:
                {error_message}
                
                Here is the history of previous errors encountered with this query:
                {chr(10).join(error_history[:-1]) if error_history[:-1] else "No previous errors in this sequence."}

                **Please generate corrected Python code.** Keep the following in mind:
                1.  **Strictly adhere to the previous instructions:** No `import` statements, no `print()` calls, and the final result MUST be assigned to `final_df` as a Pandas DataFrame.
                2.  **Focus on the error:** Analyze the error message (`{error_message}`) to understand the root cause.
                3.  **Common fixes:**
                    *   **Type Conversion Issues:** If the error indicates a type mismatch (e.g., 'could not convert string to float', 'unsupported operand types'), use `pd.to_numeric(..., errors='coerce')`, `df['column'].astype(str)`, or `pd.to_datetime(..., errors='coerce')` for the relevant columns.
                    *   **Missing Column/KeyError:** Verify column names against the provided `df_preview` and `df_types`. Ensure you're using the exact column names.
                    *   **NaN Handling:** If calculations fail due to `NaN`s, consider `.dropna()`, `.fillna()`, or using aggregation methods that handle `NaN`s (e.g., `sum(skipna=True)`).
                    *   **Logic Errors:** If the error is not syntactic but logical (e.g., trying to average a non-numeric column after type conversion), re-evaluate the pandas operation.
                4.  **Avoid previous mistakes:** Review the `error_history` to ensure you don't repeat the same error.
                5.  **Output Format:** Wrap your corrected Python code within `<result></result>` XML tags.
                """
                
                # ì£¼ì„: LLMì—ê²Œ ìˆ˜ì •ëœ ì½”ë“œë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.
                corrected_response = call_gemini_api(error_prompt)
                corrected_code = extract_code_from_response(corrected_response)
                
                if corrected_code and corrected_code != current_code: # ì£¼ì„: ìœ íš¨í•œ ìƒˆ ì½”ë“œê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    st.info("LLM provided a corrected code. Retrying with the new code.") # ì£¼ì„: ìˆ˜ì •ëœ ì½”ë“œ ìˆ˜ì‹  ì•Œë¦¼
                    current_code = corrected_code
                else:
                    return f"Failed to get a corrected or different code from LLM after error: {error_message}. Error history: {chr(10).join(error_history)}"
            else:
                # ì£¼ì„: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ì— ë„ë‹¬í•œ ê²½ìš° ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                return f"Maximum retry attempts ({max_retries}) reached. Failed to execute code. Error history: {chr(10).join(error_history)}"
    
    # ì£¼ì„: ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° (ì´ë¡ ì ìœ¼ë¡œ ì—¬ê¸°ì— ë„ë‹¬í•´ì„œëŠ” ì•ˆ ë¨)
    return f"An unexpected error occurred after all retries. Error history: {chr(10).join(error_history)}"


def generate_final_answer_prompt(user_query: str, filtered_df: pd.DataFrame) -> str:
    """
    # ì£¼ì„: í•„í„°ë§ë˜ê±°ë‚˜ ë¶„ì„ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆì˜ì— ëŒ€í•œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    # ì£¼ì„: ì´ í”„ë¡¬í”„íŠ¸ëŠ” LLMì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
    """
    # ì£¼ì„: DataFrameì„ JSON ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. LLMì´ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í•©ë‹ˆë‹¤.
    # ì£¼ì„: orient="records"ëŠ” ê° í–‰ì„ ê°ì²´ë¡œ í‘œí˜„í•˜ëŠ” JSON ë°°ì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
    # ì£¼ì„: force_ascii=FalseëŠ” í•œêµ­ì–´ ë¬¸ìê°€ ì˜¬ë°”ë¥´ê²Œ ì¸ì½”ë”©ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    try:
        if not filtered_df.empty:
            filtered_json = filtered_df.to_json(orient="records", force_ascii=False, indent=2)
        else:
            filtered_json = "[]" # ì£¼ì„: DataFrameì´ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë³´ëƒ…ë‹ˆë‹¤.
    except Exception as e:
        filtered_json = "[]" # ì£¼ì„: JSON ë³€í™˜ ì‹¤íŒ¨ ì‹œ ë¹„ì–´ìˆëŠ” ë°°ì—´ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
        st.warning(f"Failed to convert `filtered_df` to JSON for final prompt: {e}. Sending an empty array.") # ì£¼ì„: JSON ë³€í™˜ ì‹¤íŒ¨ ê²½ê³ 
    
    # ì£¼ì„: ìµœì¢… ë‹µë³€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±. LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì§€ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.
    prompt = f"""
    You are a helpful and concise data analysis assistant. Your role is to provide a clear and direct answer to the user's question based *solely* on the provided `Analyzed Data`.

    **Context:**
    - **User Query:** "{user_query}"
    - **Analyzed Data (JSON format):**
    ```json
    {filtered_json}
    ```

    **Instructions for generating the answer:**
    1.  **Direct Answer:** Provide a concise, clear, and direct answer to the user's query.
    2.  **Data-Driven:** Your answer must be entirely derived from the `Analyzed Data` provided. Do not use any external knowledge.
    3.  **Highlight Key Findings:** If applicable, summarize the most important insights or trends visible in the `Analyzed Data` that relate to the query.
    4.  **Handle Empty Data:** If the `Analyzed Data` is empty or does not contain sufficient information to answer the query, explicitly state that the answer cannot be determined from the provided data.
    5.  **Language:** The answer must be in Korean.
    6.  **Formatting:** Avoid unnecessary formatting, special characters, or code blocks in your final answer. Just plain, clear text.
    """
    return prompt

# --- Streamlit Application ---

def main():
    """
    # ì£¼ì„: Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    # ì£¼ì„: íŒŒì¼ ì—…ë¡œë“œ, ì§ˆë¬¸ ì…ë ¥, LLM í˜¸ì¶œ, ì½”ë“œ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œì˜ ì „ì²´ ì›Œí¬í”Œë¡œìš°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    # ì£¼ì„: Streamlit í˜ì´ì§€ì˜ ê¸°ë³¸ ì„¤ì • (ì „ì²´ ë„ˆë¹„, í˜ì´ì§€ ì œëª©)
    st.set_page_config(layout="wide", page_title="AI Data Analysis Assistant")
    st.title("AI Data Analysis Assistant")
    st.markdown("Upload your Excel or CSV file and ask questions. The AI will generate and execute Python code to analyze your data and provide answers.")

    uploaded_file = st.file_uploader("Upload your data file (Excel or CSV)", type=["xls", "xlsx", "csv"])

    df: pd.DataFrame | None = None # ì£¼ì„: ì—…ë¡œë“œëœ íŒŒì¼ì„ ì €ì¥í•  DataFrame ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
    if uploaded_file:
        file_type = uploaded_file.name.split('.')[-1].lower()
        
        st.info(f"Loading `{uploaded_file.name}` (type: {file_type})...") # ì£¼ì„: íŒŒì¼ ë¡œë”© ì‹œì‘ ì•Œë¦¼
        try:
            if file_type == 'csv':
                # ì£¼ì„: CSV íŒŒì¼ ë¡œë“œ. ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„ (utf-8ì´ ì‹¤íŒ¨í•  ê²½ìš°).
                try:
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                except UnicodeDecodeError:
                    df = pd.read_csv(uploaded_file, encoding='cp949') # ì£¼ì„: í•œêµ­ì–´ ì¸ì½”ë”© ì‹œë„
            else:
                # ì£¼ì„: Excel íŒŒì¼ ë¡œë“œ.
                df = pd.read_excel(uploaded_file)
            st.success("File loaded successfully! ğŸ‰") # ì£¼ì„: íŒŒì¼ ë¡œë“œ ì„±ê³µ ì•Œë¦¼
        except Exception as e:
            st.error(f"Error loading file: `{e}`. Please ensure it's a valid {file_type} file and try again.") # ì£¼ì„: íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ë©”ì‹œì§€
            return # ì£¼ì„: íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.

        # --- Display Data Previews for User and LLM ---
        with st.expander("ğŸ‘ï¸ Data Preview (for Human)"):
            st.dataframe(df.head(10)) # ì£¼ì„: ì‚¬ìš©ìì—ê²Œ ì²˜ìŒ 10ê°œ í–‰ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

        # ì£¼ì„: LLMì— ë³´ë‚¼ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 5ê°œ í–‰ë§Œ)
        df_preview = df.head(5).to_dict(orient="records")
        with st.expander("ğŸ¤– Data Preview (for LLM - first 5 rows in JSON)"):
            st.json(df_preview)
        
        # ì£¼ì„: LLMì— ë³´ë‚¼ DataFrameì˜ ê° ì»¬ëŸ¼ ë°ì´í„° íƒ€ì… ì •ë³´
        df_types = df.dtypes.apply(lambda x: str(x)).to_dict()
        with st.expander("ğŸ¤– Data Types (for LLM in JSON)"):
            st.json(df_types)
        
        # --- Example Questions for User Convenience ---
        example_questions = [
            "What are the top 5 administrative districts by the total number of stores in Seoul, categorized by major business type?",
            "Which administrative district in Seoul has the highest average floor count for cafes?", 
            "In Seoul, which area has the highest proportion of real estate agencies out of all commercial stores?",
            "What is the proportion of stores by sub-business type (ì¤‘ë¶„ë¥˜) in Seongdong-gu?",
            "Show me the average floor count for all stores in Gangnam-gu, grouped by major business type.",
            "Can you give me the number of stores in each 'í–‰ì •êµ¬' (administrative district)?"
        ]

        # ì£¼ì„: Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì§ˆì˜ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
        if "user_query" not in st.session_state:
            st.session_state["user_query"] = ""

        # --- User Input Area ---
        user_input = st.text_input(
            "ğŸ“ Ask a question about your data:",
            value=st.session_state["user_query"], # ì£¼ì„: ì´ì „ì— ì…ë ¥ëœ ì§ˆì˜ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
            key="input_box",
            help="Enter your question here or select from the examples below."
        )

        # ì£¼ì„: ì‚¬ìš©ìê°€ ì…ë ¥ì´ ì—†ìœ¼ë©´ ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        user_query_to_process = user_input
        if not user_input:
            sample_query = st.selectbox("Or select an example question:", [""] + example_questions, key="sample_box")
            user_query_to_process = sample_query

        # --- "Get Answer" Button ---
        if st.button("ğŸš€ Get Answer", type="primary"):
            st.session_state["user_query"] = user_query_to_process # ì£¼ì„: í˜„ì¬ ì§ˆì˜ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
            if not user_query_to_process:
                st.warning("Please enter a question or select an example to get started.")
                return # ì£¼ì„: ì§ˆì˜ê°€ ì—†ìœ¼ë©´ í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.

            st.markdown("---")
            st.subheader("ğŸ’¡ Processing your request...")
            
            # 1. Generate Code Prompt for LLM
            # ì£¼ì„: ì‚¬ìš©ì ì§ˆì˜ì™€ ë°ì´í„° ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì—ê²Œ ì½”ë“œ ìƒì„±ì„ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
            code_prompt = generate_code_prompt(user_query_to_process, df_preview, df_types)
            # with st.expander("ğŸ“„ Generated Code Prompt (for LLM)"): # ì£¼ì„: ë””ë²„ê¹…ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ìˆ¨ê¹€/í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            #     st.code(code_prompt, language="markdown")

            # 2. Call LLM to Generate Code
            # ì£¼ì„: Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ Pandas ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            generated_response = call_gemini_api(code_prompt)
            if "ERROR" in generated_response:
                st.error("Failed to generate code from LLM due to an API error.")
                return

            # ì£¼ì„: LLM ì‘ë‹µì—ì„œ ì‹¤ì œ Python ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            generated_code = extract_code_from_response(generated_response)
            if not generated_code:
                st.error("Could not extract Python code from LLM's response. Please try rephrasing your question or check the raw LLM response below.")
                with st.expander("Raw LLM Response"): # ì£¼ì„: ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‘ë‹µì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
                    st.code(generated_response, language="markdown", help="This is the raw output from the LLM.")
                return

            # 3. Execute Generated Code
            # ì£¼ì„: ìƒì„±ëœ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ê³ , ì˜¤ë¥˜ ë°œìƒ ì‹œ LLMì—ê²Œ ìˆ˜ì •ì„ ìš”ì²­í•˜ë©° ì¬ì‹œë„í•©ë‹ˆë‹¤.
            filtered_df_or_error = execute_generated_code(generated_code, df)
            
            if isinstance(filtered_df_or_error, pd.DataFrame):
                # 4. Generate Final Answer Prompt
                # ì£¼ì„: í•„í„°ë§ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.
                final_answer_prompt = generate_final_answer_prompt(user_query_to_process, filtered_df_or_error)
                # with st.expander("ğŸ“„ Final Answer Prompt (for LLM)"): # ì£¼ì„: ë””ë²„ê¹…ì„ ìœ„í•´ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì„ ìˆ¨ê¹€/í‘œì‹œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                #     st.code(final_answer_prompt, language="json")
                
                # 5. Call LLM for Final Answer
                # ì£¼ì„: Gemini APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì¢… ìì—°ì–´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
                final_response = call_gemini_api(final_answer_prompt)
                if "ERROR" in final_response:
                    st.error("Failed to generate final answer from LLM.")
                    return

                # --- Display Results to User ---
                st.subheader("âœ… Answer")
                st.success(final_response) # ì£¼ì„: ìµœì¢… ë‹µë³€ì„ ì‚¬ìš©ìì—ê²Œ í‘œì‹œí•©ë‹ˆë‹¤.
                
                with st.expander("ğŸ” Detailed Analysis (for debugging and transparency)"):
                    st.markdown("---")
                    st.subheader("Generated Python Code")
                    st.code(generated_code, language="python")

                    st.subheader("Intermediate Filtered/Analyzed Data") 
                    if not filtered_df_or_error.empty:
                        st.dataframe(filtered_df_or_error)
                    else:
                        st.info("The generated code resulted in an empty DataFrame. This might mean no data matched your query or the analysis produced no results.")
                                                
                    st.subheader("LLM Prompt used for Final Answer Generation")
                    st.code(final_answer_prompt, language="json")

            else:
                # ì£¼ì„: ì½”ë“œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
                st.error(f"An error occurred during code execution that could not be resolved: {filtered_df_or_error}")

if __name__ == "__main__":
    main()